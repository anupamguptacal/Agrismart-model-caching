# Agrismart-model-caching
With the rise of the adoption of machine learning in everyday areas of life, we are often surrounded by systems housing multiple models aimed towards accurate task performance. We explore the setting of a large scale of locally differentiated machine learning models that are organized together in a hierarchy with multiple tiers. We aim to understand how to optimize continuous tier-specific inference in these settings while optimizing for network costs, storage space and local privacy constraints. This paper explores two intuitive frameworks in this regard and performs thorough comparative analysis outlining numeric support points for the approaches. The paper also introduces a dynamic novel protocol, termed MITM, that combines the benefits of the previously introduced protocol using a novel meet-in-the-middle staggered model caching approach. Thorough testing and analysis of MITM on a distributed agricultural disease-prediction dataset displays the superiority of the novel protocol over the previously introduced frameworks, demonstrating a reduction of up to 80\% in real-time communication cost, 80\% in memory utilization and 50\% in inference latency while maintaining comparable metrics of accuracy at even higher levels of any hierarchical intelligent framework.
